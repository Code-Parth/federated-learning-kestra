id: federated-learning
namespace: ml_workflows
inputs:
  - name: num_institutions
    type: INT
    default: 50
  - name: num_samples
    type: INT
    default: 5000
  - name: random_seed
    type: INT
    default: 42

tasks:
  - id: setup_environment
    type: bash
    commands:
      - mkdir -p logs results outputs
      - pip install -r requirements.txt

  - id: generate_data
    type: python
    properties:
      # Python script to generate and save institution-specific data
      script: |
        from federated_learning.data_generator import DataGenerator
        import os

        def generate_institution_data(num_institutions, num_samples):
            os.makedirs('data', exist_ok=True)
            data_generator = DataGenerator(num_samples=num_samples)
            
            for i in range(num_institutions):
                institution_data = data_generator.generate_credit_data()
                data_generator.save_data(institution_data, f'data/institution_{i+1}_data.pkl')

        generate_institution_data({{inputs.num_institutions}}, {{inputs.num_samples}})
    dependsOn:
      - setup_environment

  - id: train_local_models
    type: python
    properties:
      script: |
        import os
        import json
        from federated_learning.data_generator import DataGenerator
        from federated_learning.local_model import LocalModel

        def train_local_models(num_institutions):
            local_models = []
            
            for i in range(num_institutions):
                data_path = f'data/institution_{i+1}_data.pkl'
                data_generator = DataGenerator()
                institution_data = data_generator.load_data(data_path)
                
                local_model = LocalModel(institution_data)
                local_model_result = local_model.train()
                
                local_models.append(local_model_result)
            
            # Save local models for aggregation
            with open('local_models.json', 'w') as f:
                json.dump(local_models, f)
            
            print(f"Trained {num_institutions} local models")

        train_local_models({{inputs.num_institutions}})
    dependsOn:
      - generate_data

  - id: aggregate_models
    type: python
    properties:
      script: |
        import json
        import os
        from federated_learning.aggregator import ModelAggregator

        def aggregate_local_models():
            with open('local_models.json', 'r') as f:
                local_models = json.load(f)
            
            aggregator = ModelAggregator(local_models)
            global_model = aggregator.federated_averaging()
            
            # Save global model results
            with open('global_model.json', 'w') as f:
                json.dump({
                    'global_performance': float(global_model['global_performance']),
                    'global_weights': global_model['global_weights'].tolist()
                }, f, indent=4)
            
            print("Global model aggregation complete")

        aggregate_local_models()
    dependsOn:
      - train_local_models

  - id: generate_visualizations
    type: python
    properties:
      script: |
        import json
        import matplotlib.pyplot as plt
        import numpy as np

        def create_visualizations():
            with open('local_models.json', 'r') as f:
                local_models = json.load(f)
            
            with open('global_model.json', 'r') as f:
                global_model = json.load(f)
            
            # Local model performance visualization
            local_scores = [model['local_score'] for model in local_models]
            
            plt.figure(figsize=(10, 6))
            plt.bar(range(len(local_scores)), local_scores, color='blue', alpha=0.6)
            plt.axhline(y=global_model['global_performance'], color='r', linestyle='--', label='Global Performance')
            plt.title('Local Model Performance Comparison')
            plt.xlabel('Local Model Index')
            plt.ylabel('RÂ² Score')
            plt.legend()
            plt.tight_layout()
            plt.savefig('outputs/local_model_performance.png')
            plt.close()
            
            # Create weight distribution visualization
            global_weights = np.array(global_model['global_weights'])
            
            plt.figure(figsize=(10, 6))
            plt.bar(range(len(global_weights)), global_weights, color='green', alpha=0.6)
            plt.title('Global Model Feature Weights')
            plt.xlabel('Feature Index')
            plt.ylabel('Weight')
            plt.tight_layout()
            plt.savefig('outputs/global_model_weights.png')
            plt.close()
            
            print("Visualizations generated")

        create_visualizations()
    dependsOn:
      - aggregate_models

  - id: log_results
    type: bash
    commands:
      - echo "Federated Learning Workflow Completed"
      - cat global_model.json
    dependsOn:
      - generate_visualizations

outputs:
  - from: outputs/local_model_performance.png
    type: FILE
  - from: outputs/global_model_weights.png
    type: FILE
  - from: global_model.json
    type: FILE

catch:
  - id: error_handler
    type: bash
    commands:
      - echo "Workflow failed. Check logs for details."
      - cat logs/*
